# Functions for "multi-armed bandit" sampler from Battiston et al. (2018)


#' HPY sampler from Battiston et al. (2018)
#'
#' @param Y Matrix of taxa counts (rows are populations, columns are species)
#' @param n.iter Number of MCMC iterations (after burn-in)
#' @param quiet If TRUE, console output is suppressed
#' @param n.burn Number of burn-in iterations
#'
#' @return
#' @export
#' @importFrom parallel mclapply
#'
#' @examples
b_sampler <- function(Y, n.iter, n.burn, p.shape, p.scale, p.shape.pop=NULL, p.scale.pop=NULL, type=c("py", "dp"),
                      n.cores=1, quiet=FALSE) {
  if (!is.numeric(Y) | !is.matrix(Y) |
      any(Y<0) | any(Y!=floor(Y))) stop("Y must be a numeric matrix of positive counts")
  
  type <- match.arg(type)
  
  J <- NROW(Y)
  K <- NCOL(Y) # Number of distinct species in joint sample
  
  if (is.null(p.shape.pop)) {
    p.shape.pop <- rep(p.shape, J)
  }
  if (is.null(p.scale.pop)) {
    p.scale.pop <- rep(p.scale, J)
  }
  
  # Initializing PY parameters
  # CURRENTLY FIXING SOME PARAMS TO SIMULATED VALUES... REMEMBER TO CHANGE BACK
  gamma <- 5 #tmp <<- conc.top # Top-level concentation
  alpha <- ifelse(type=="dp", 0, 0.5)  #tmp <<- dsct.top # Top-level discount
  theta <- rep(1, J) # tmp <<- conc.local # Population-level concentration
  if(type=="dp") {
    sigma <- rep(0, J)
  } else {
    sigma <- rep(0.5, J) # tmp <<- dsct.local # Population-level discount
  }
  
  # Initializing table info
  sp.vec <- vector("list", length=J)
  n <- rowSums(Y) # The number of individuals in each population
  tab <- vector("list", length=J) # List to hold table indicators for each population
  t.c <- vector("list", length=J) # Table counts (and species corresponding to each table)
  n.tab <- rep(0, J) # Number of tables in each population
  #n.s.tab <- matrix(1, J, K) # Number of tables for a given species in each population
  n.s.tab <- 1*(Y>0) # Number of tables for a given species in each population
  for (j in 1:J) {
    # Initially one table for each species
    sp.vec[[j]] <- rep(1:K, Y[j,])
    tab[[j]] <- rep(1:sum(Y[j,]>0), c(Y[j,])[Y[j,]>0])
    t.c[[j]] <- cbind((1:K)[Y[j,]>0], c(Y[j,])[Y[j,]>0])
    n.tab[j] <- NROW(t.c[[j]])
  }
  mc.list <- vector("list", length=J) # List for mclapply
  
  gamma.s <- rep(0, n.iter)
  alpha.s <- rep(0, n.iter)
  theta.s <- matrix(0, n.iter, J)
  sigma.s <- matrix(0, n.iter, J)
  n.tab.s <- matrix(0, n.iter, J)
  n.s.tab.s <- array(0, dim=c(n.iter, J, K))
  t.c.s <- vector("list", length=n.iter)

  # Loop over MCMC iterations
  for (i in 1:(n.burn+n.iter)) {
    cat("i =", i, "\n")
    idx <- i - n.burn
    
    if (!quiet & i==1) cat("Beginning burn-in:", "\n")
    if (!quiet & i==n.burn+1) cat("Beginning sampling:", "\n")
    if (!quiet & i%%100==0) cat(" ", i, "\n")
    
    # TEMP: Setting table info to true values
    # REMEMBER TO DELETE THIS
    #n.tab <- s.hpy$t.tab
    #n.s.tab <- s.hpy$n.s.tab
    
    # Loop over populations
    for (j in 1:J) {
      #cat("j =", j, "\n")
      #Loop over individuals in a population
      for (p in 1:n[j]){
        sp.cur <- sp.vec[[j]][p]
        # Remove current individual from its table
        t.cur <- tab[[j]][p]
        t.c[[j]][t.cur,2] <- t.c[[j]][t.cur,2] - 1
        if (t.c[[j]][t.cur,2]==0) {
          # Drop table and make adjustments
          t.c[[j]] <- t.c[[j]][-t.cur,]
          tab[[j]][tab[[j]]>t.cur] <- tab[[j]][tab[[j]]>t.cur] - 1
          n.tab[j] <- n.tab[j] - 1
          n.s.tab[j, sp.cur] <- n.s.tab[j, sp.cur] - 1
        }

        # Reassign individual to new or existing table
        npart <- (gamma+sum(n.tab))*(Y[j,sp.cur]-1-n.s.tab[j, sp.cur]*sigma[j])
        dpart <- (theta[j]+n.tab[j]*sigma[j])*(sum(n.s.tab[, sp.cur])-alpha)
        prob.new <- ifelse(n.s.tab[j, sp.cur]==0, 1, 1/(1+npart/dpart))
        is.new <- rbinom(1, 1, prob.new)
        if (is.new) {
          # Allocate new table
          t.c[[j]] <- rbind(t.c[[j]], c(sp.cur, 1))
          n.tab[j] <- n.tab[j] + 1
          n.s.tab[j, sp.cur] <- n.s.tab[j, sp.cur] + 1
          tab[[j]][p] <- n.tab[j]
        } else {
          #if (i==8 & p==50) browser()
          # Sample existing table (from proper species)
          #freq.t <- ifelse(t.c[[j]][,1]==sp.cur, (t.c[[j]][,2]-sigma[j])/(theta[j]+n[j]-1), 0)
          #freq.t <- ifelse(t.c[[j]][,1]==sp.cur, t.c[[j]][,2]-sigma[j], 0)
          #freq.t <- rep(0, n.tab[j])
          #freq.t[t.c[[j]][,1]==sp.cur] <- t.c[[j]][t.c[[j]][,1]==sp.cur,2]-sigma[j]
          #wh.t <- sample(1:length(freq.t), 1, prob=freq.t)
          wh.c.sp <- which(t.c[[j]][,1]==sp.cur)
          wh.t.new <- sample(1:length(wh.c.sp), 1, prob=(t.c[[j]][wh.c.sp,2]-sigma[j]))
          wh.t <- wh.c.sp[wh.t.new]
          t.c[[j]][wh.t, 2] <- t.c[[j]][wh.t, 2] + 1
          tab[[j]][p] <- wh.t
        }
      }

      # Putting relevant quantities into list for use in mclapply
      # mc.list[[j]] <- list(conc=theta[j],n.tab=n.tab[j],n=n[j],
      #                      dsct=sigma[j], n.s.tab=n.s.tab[j,,drop=FALSE],
      #                      Y=Y[j,,drop=FALSE], J=1, p.shape=p.shape,
      #                      p.scale=p.scale)

      ###sigma[j] <- samp_dsct(sigma[j], theta[j], n.tab[j],
      ###                      n.s.tab[j,,drop=FALSE], Y[j,,drop=FALSE])
      if (type=="py") {
        sigma[j] <- gStirling::sampDsct(sigma[j], K, n.tab[j],Y[j,,drop=FALSE], n.s.tab[j,,drop=FALSE], theta[j])
      }
      ###theta[j] <- samp_conc(theta[j], p.shape, p.scale, n.tab[j], 1, n[j], sigma[j])
      theta[j] <- gStirling::sampConc(theta[j], n[j], n.tab[j], p.shape.pop[j], p.scale.pop[j], sigma[j])
    }
    
    # Sample local-level PY parameters
    #theta <- unlist(parallel::mclapply(mc.list, samp_conc_list, mc.cores = n.cores))
    #sigma <- unlist(parallel::mclapply(mc.list, samp_dsct_list, mc.cores = n.cores))
    
    for (j in 1:J) {
      if (i>n.burn) {
        theta.s[idx,j] <- theta[j]
        sigma.s[idx,j] <- sigma[j]
        n.tab.s[idx,j] <- n.tab[j]
      }
    }
    
    # Sample top-level PY parameters
    # Discount
    sp.tab.totals <- matrix(apply(n.s.tab, 2, sum), ncol=K)
    ###alpha <- samp_dsct(alpha, gamma, K, matrix(1,ncol=K), sp.tab.totals)
    if (type=="py") {
      alpha <- gStirling::sampDsct(alpha, K, K, sp.tab.totals, t(rep(1, K)), gamma) # Chris
    }
    # Concentration
    ###gamma <- samp_conc(gamma, p.shape, p.scale, K, 1, sum(n.tab), alpha)
    gamma <- gStirling::sampConc(gamma, sum(n.tab), K, p.shape, p.scale, alpha)
    
    if (i>n.burn) {
      gamma.s[idx] <- gamma
      alpha.s[idx] <- alpha
      n.s.tab.s[idx,,] <- n.s.tab
      t.c.s[[idx]] <- t.c
    }
  }
  
  return(list(gamma=gamma.s, alpha=alpha.s, theta=theta.s, sigma=sigma.s,
              tab=tab, t.c=t.c.s, n.tab=n.tab.s, n.s.tab=n.s.tab.s,
              p.shape=p.shape, p.scale=p.scale))
}

#' PY Gibbs sampler (non-hierarchical) Really this is for GEM
#'
#' @param Y Matrix of taxa counts (rows are populations, columns are species)
#' @param n.iter Number of MCMC iterations (after burn-in)
#' @param quiet If TRUE, console output is suppressed
#' @param n.burn Number of burn-in iterations
#'
#' @return
#' @export
#'
#' @examples
b_sampler_py <- function(Y, n.iter, n.burn, p.shape, p.scale, quiet=FALSE,
                         code=c("buntine","kevin"), init=c(1, 0.5),
                         suppress.gamma=FALSE, suppress.alpha=FALSE) {
  if (!is.numeric(Y) | !is.vector(Y) |
      any(Y<0) | any(Y!=floor(Y))) stop("Y must be a numeric matrix of positive counts")
  
  code <- match.arg(code)
  
  # Initalize params
  gamma <- init[1] # Concentation
  alpha <- init[2]  # Discount
  
  N <- sum(Y)
  K <- length(Y)
  
  # DON'T SAMPLE TABLE INDICATORS FOR THIS 
  # sp.vec <- rep(1:K, Y)
  # n.s.tab <- rep(1, K) # Number of tables for each species
  # tab <- rep(1:sum(Y>0), Y[Y>0]) # Table indicator for each individual, initially one table for each species
  # t.c <- cbind((1:K)[Y>0], Y[Y>0]) # Table counts (and species corresponding to each table)
  # n.tab <- NROW(t.c) # Number of tables
  # 
  gamma.s <- rep(0, n.iter)
  alpha.s <- rep(0, n.iter)
  # n.tab.s <- rep(0, n.iter)
  # n.s.tab.s <- array(0, dim=c(n.iter, K))
  
  for (i in 1:(n.burn+n.iter)) {
    #cat("i =", i, "\n")
    idx <- i - n.burn
    
    if (!quiet & i==1) cat("Beginning burn-in:", "\n")
    if (!quiet & i==n.burn+1) cat("Beginning sampling:", "\n")
    if (!quiet & i%%100==0) cat(" ", i, "\n")
    
    # DON'T SAMPLE TABLE INDICATORS FOR THIS 
    # for (p in 1:N){
    #   sp.cur <- sp.vec[p]
    #   # Remove current individual from its table
    #   t.cur <- tab[p]
    #   t.c[t.cur,2] <- t.c[t.cur,2] - 1
    #   if (t.c[t.cur,2]==0) {
    #     # Drop table and make adjustments
    #     t.c <- t.c[-t.cur,]
    #     tab[tab>t.cur] <- tab[tab>t.cur] - 1
    #     n.tab <- n.tab - 1
    #     n.s.tab[sp.cur] <- n.s.tab[sp.cur] - 1
    #   }
    #   
    #   # Reassign individual to new or existing table (from tables corresponding to that particular species)
    #   #if (i==300) browser()
    #   prob.new <- (gamma+n.s.tab[sp.cur]*alpha)/(Y[sp.cur]-1+gamma)
    #   is.new <- rbinom(1, 1, prob.new)
    #   #if (is.na(is.new)) browser()
    #   if (is.new) {
    #     # Allocate new table
    #     t.c <- rbind(t.c, c(sp.cur, 1))
    #     n.tab <- n.tab + 1
    #     n.s.tab[sp.cur] <- n.s.tab[sp.cur] + 1
    #     tab[p] <- n.tab
    #   } else {
    #     # Sample existing table (from proper species)
    #     freq.t <- ifelse(t.c[,1]==sp.cur, t.c[,2]-alpha, 0)
    #     wh.t <- sample(1:length(freq.t), 1, prob=freq.t)
    #     t.c[wh.t, 2] <- t.c[wh.t, 2] + 1
    #     tab[p] <- wh.t
    #   }
    # }
    
    #print("hello")
    
    # Sample PY parameters
    if (!suppress.gamma) {
      if (code=="buntine") {
        gamma <- gStirling::sampConc(gamma, N, K, p.shape, p.scale, alpha, 1) # Buntine
      } else {
        gamma <- samp_conc(conc, p.shape, p.scale, K, N, dsct)
      }
    }
    if (!suppress.alpha) {
      alpha <- gStirling::sampDsct(alpha, K, K, matrix(Y, nrow=1), t(rep(1, K)), gamma)
    }
    # Save parameters for current MCMC iteration
    if (i>n.burn) {
      gamma.s[idx] <- gamma
      alpha.s[idx] <- alpha
      #n.tab.s[idx] <- n.tab
      #n.s.tab.s[idx,] <- n.s.tab
    }
  }
  
  # return(list(gamma=gamma.s, alpha=alpha.s, tab=tab, t.c=t.c, n.tab=n.tab.s, n.s.tab=n.s.tab.s,
  #             p.shape=p.shape, p.scale=p.scale))
  return(list(gamma=gamma.s, alpha=alpha.s, p.shape=p.shape, p.scale=p.scale))
}

#' Sample the concentration parameter hierarchical in Pitman-Yor process
#' REMOVED NUMBER OF POPULATIONS J FROM THIS!!!
#'
#' @param conc Current value of the concentration parameter
#' @param n 
#'
#' @return
#' @export
#'
#' @examples
samp_conc <- function(conc, p.shape, p.scale, n.tab, n, dsct, Q=NULL) {
  max.conc <- 2000
  
  # Sample auxiliary Beta variables
  if (is.null(Q)) {
    q <- rbeta(1, conc, n)
    Q <- 1/p.scale - log(q)
  }
  #cat("Q = ", Q, "\n")
  
  conc.map <- map_conc(conc, p.shape, Q, n.tab, dsct)
  #cat("conc.map = ", conc.map, "\n")
  conc.ret <- slice(conc.map, prob_conc, max=max.conc, p.shape=p.shape, 
                         Q=Q, n.tab=n.tab, dsct=dsct)

  return(conc.ret)
}

# Wrapper function for samp_conc for use in mclapply
samp_conc_list <- function(l) {
  samp_conc(l$conc, l$p.shape, l$p.scale, l$n.tab, l$J, l$n, l$dsct)
}

# Sample discount parameter
#samp_dsct <- function(dsct, conc, n.tab, n.s.tab, Y) {
samp_dsct <- function(dsct, conc, n.tab, n.s.tab, Y, iter=10) {
  dsct.ret <- slice(dsct, prob_dsct, min=0, max=1, iter=iter,
                    conc=conc, n.tab=n.tab, n.s.tab=n.s.tab, Y=Y)
  return(dsct.ret)
}

# Wrapper function for samp_dsct for use in mclapply
samp_dsct_list <- function(l) {
  samp_dsct(l$dsct, l$conc, l$n.tab, l$n.s.tab, l$Y)
}

#' Inverse digamma function
#'
#' @param x The value at which to evaluate the inverse of the digamma function 
#'
#' @return The inverse of the digamma function evaluated at x
#' @export
#'
#' @examples
inv_digamma <- function(x) {
  if (x<(-2.22)) {
    g <- -1/(x-digamma(1))
  } else {
    g <- exp(x)+0.5
  }
  
  for(i in 1:5) {
    g <- g - (digamma(g)-x)/trigamma(g)
  }
  
  return(g)
}


map_conc <- function(conc, p.shape, Q, n.tab, dsct, err.tol=1e-4, max.iter=10) {
  #J <- length(n.tab)
  i <- 1
  conc.old <- conc*1.1
  while (i < max.iter & abs((conc-conc.old)/conc) > err.tol) {
    #print(conc)
    conc.old <- conc
    p <- sum(digamma(n.tab+conc/dsct))
    p <- p + dsct*(p.shape-1)/(conc) - dsct*Q
    conc <- dsct*inv_digamma(p)
    i <- i + 1
  }
  if (i==max.iter) stop("MAP estimation failed to converge")
  return(conc)
}

prob_conc <- function(conc, p.shape, Q, n.tab, dsct) {
  lg <- lgamma(conc/dsct)
  log_prob <- -conc*Q+(p.shape-1)*log(conc)
  log_prob <- log_prob + sum(lgamma(n.tab+conc/dsct) - lg)
  return(log_prob)
}


#' Title
#'
#' @param dsct 
#' @param conc 
#' @param n.tab 
#' @param n.s.tab 
#' @param Y 
#' @param s.table Optional: previously calculated Stirling number table
#' to reuse for faster computation
#'
#' @return
#' @importFrom gStirling gStirling
#' @export
#'
#' @examples
# prob_dsct <- function(dsct, conc, n.tab, n.s.tab, Y, s.table=NULL) {
prob_dsct <- function(dsct, conc, n.tab, n.s.tab, Y, s.table=NULL) {
  #if (is.na(dsct)) browser()
  K <- NROW(Y)
  
  # Find max Stirling number to calculate
  mt <- max(n.s.tab)
  my <- max(Y)
  if (is.null(s.table)) {
    s.table <- gStirling::gStirling(my, mt, dsct)
  }

  # Adding the log-Stirling numbers
  log_prob <- 0
  for (i in 1:NROW(Y)) {
    wh.pos <- which(Y[i,]>0)
    log_prob <- log_prob + sum(s.table[Y[i,wh.pos]+my*(n.s.tab[i,wh.pos]-1)])
  }
  
  lg <- lgamma(conc/dsct)
  log_prob <- log_prob + n.tab*log(dsct) + lgamma(n.tab+conc/dsct) - lg

  return(log_prob)
}

#' Slice sampler for a single parameter
#'
#' @param map Initial value of parameter, possibly an MAP estimate
#' @param l.prob Log-probability density function for parameter
#' @param iter Number of iterations to run slice sampler (can be small)
#' @param min Minimum bound for parameter
#' @param max Maximum bound for parameter
#' @param ... Arguments passed on to l.prob()
#'
#' @return A sample from the distribution characterized by l.prob()
#' @export
#'
#' @examples
slice <- function(map, l.prob, iter=25, min=0, max, ...) {
  bounds <- c(min, max)
  x <- map
  #cat("start:\n")
  for (i in 1:iter) {
    y <- l.prob(x, ...)
    l <- bounds[1]
    r <- bounds[2]
    y <- y + log(runif(1))
    accept <- FALSE
    while (!accept) {
      x.try <- l + runif(1)*(r-l)
      #cat("l = ", l, ", x.try = ", x.try, ", r = ", r, "\n")
      #if (is.na(l.prob(x.try, ...)) | is.na(y)) browser()
      if (l.prob(x.try, ...) > y) {
        x <- x.try
        accept <- TRUE
        #cat("sample=", x, "\n")
      } else {
        if (x.try < x) {
          l <- x.try
        } else {
          r <- x.try
        }
      }
    }
  }
  
  return(x)
}


#' Get Simpson's diversity index based on estimated hierarchical Pitman-Yor model
#' newer, more efficient version
#' NOPE! THIS IS WRONG!!!
#'
#' @return
#' @export
#'
#' @examples
getSimpsonWrong <- function(Y, tab, n.s.tab, pop, c.top, d.top, c.loc, d.loc) {
  
  # Current table frequencies
  Y.c <- Y[pop,] # Species frequencies for this populations
  c.tab <- tab[[pop]] # Tables for population "pop"
  n.tab <- NROW(c.tab) # Number of tables in population "pop"
  n.j <- sum(c.tab[,2]) # Number of individuals in population "pop"
  n.tab.sp <- colSums(n.s.tab) # Number of tables of each species across all populations
  tot.tab <- sum(n.tab.sp) # Number of tables overall
  K <- length(n.tab.sp) # Total number of species across all populations
  
  den <- (c.loc+n.j-1)*(c.top+tot.tab-1)*(c.loc+n.j)*(c.top+tot.tab)
  
  no.sum.part <- n.tab*(c.top+K*d.top)*((c.top+tot.tab)*(1-d.loc)+(c.loc+(n.tab+1)*d.loc)*(1-d.top))
  sum.part1 <- 0
  sum.part2 <- 0
  for (t in 1:n.tab) {
    c.sp <- c.tab[t, 1] # Get species for this table
    n.t.ss <- sum(c.tab[,1]==c.sp) # Number of tables are of the same species as the current one?
    #t.t.sp <- sum(unlist(lapply(tab, function(x){sum(x[x[1,]==c.sp,2])})))
    sum.part1 <- sum.part1 + (c.tab[t,2] - d.loc)*(Y.c[c.sp]+1-n.s.tab[pop,c.sp]*d.loc)
    sum.part2 <- sum.part2 + (n.tab.sp[c.sp]-d.top)*((c.top+tot.tab)*(Y.c[c.sp]+1-(n.s.tab[pop,c.sp]+1)*d.loc) +
                                             (c.loc+(n.tab+1)*d.loc)*(n.tab.sp[c.sp]+1-d.top))
  }
  
  d <- ((c.top+tot.tab-1)*(c.top+tot.tab)*sum.part1 +
          (c.loc+n.tab*d.loc)*(no.sum.part+sum.part2))/den
  return(1-d)
}

# Might have made mistake in Simpson's index... seeing if I can fix it
getSimpson <- function(Y, tab, n.s.tab, pop, c.top, d.top, c.loc, d.loc) {
  
  # Current table frequencies
  Y.c <- Y[pop,] # Species frequencies for this populations
  c.tab <- tab[[pop]] # Tables for population "pop"
  n.tab <- NROW(c.tab) # Number of tables in population "pop"
  n.j <- sum(c.tab[,2]) # Number of individuals in population "pop"
  n.tab.sp <- colSums(n.s.tab) # Number of tables of each species across all populations
  tot.tab <- sum(n.tab.sp) # Number of tables overall
  K <- length(n.tab.sp) # Total number of species across all populations
  
  no.sum.part <- (c.top+K*d.top)/(c.top+tot.tab)*((1-d.loc)/(c.loc+n.j+1) +
                                      (c.loc+(n.tab+1)*d.loc)/(c.loc+n.tab+1)*(1-d.top)/(c.top+tot.tab+1))
  
  t.sum.part <- 0
  for (t in 1:n.tab) {
    c.sp <- c.tab[t, 1] # Get species for this table
    t.ss <- which(c.tab[,1]==c.sp) # Which other tables are of the same species as the current one?
    t.ss <- t.ss[t.ss!=t]
    t.sum.part <- t.sum.part + (c.tab[t,2]-d.loc)/(c.loc+n.j)*(
      (c.tab[t,2]+1-d.loc)/(c.loc+n.j+1) + sum((c.tab[t.ss,2]-d.loc)/(c.loc+n.j+1)) +
      (c.loc+n.tab*d.loc)/(c.loc+n.j+1)*(n.tab.sp[c.sp]-d.top)/(c.top+tot.tab))
  }
  
  k.sum.part <- 0
  for (k in 1:K) {
    t.ss <- which(c.tab[,1]==k)
    k.sum.part <- k.sum.part + (n.tab.sp[k]-d.top)/(c.top+tot.tab)*(
      (1-d.loc)/(c.loc+n.j+1) + sum((c.tab[t.ss,2]-d.loc)/(c.loc+n.j+1)) +
        (c.loc+(n.tab+1)*d.loc)/(c.loc+n.j+1)*(n.tab.sp[k]+1-d.top)/(c.top+tot.tab+1))
  }

  d <- t.sum.part + (c.loc+n.tab*d.loc)/(c.loc+n.j)*(k.sum.part + no.sum.part)
  
  return(1-d)
}

# New (correct) version of getSimpson... trying to make calculation more efficient
getSimpsonTry <- function(Y, tab, n.s.tab, pop, c.top, d.top, c.loc, d.loc) {
  
  # Current table frequencies
  Y.c <- Y[pop,] # Species frequencies for this populations
  c.tab <- tab[[pop]] # Tables for population "pop"
  n.tab <- NROW(c.tab) # Number of tables in population "pop"
  n.j <- sum(c.tab[,2]) # Number of individuals in population "pop"
  n.tab.sp <- colSums(n.s.tab) # Number of tables of each species across all populations
  tot.tab <- sum(n.tab.sp) # Number of tables overall
  K <- length(n.tab.sp) # Total number of species across all populations
  
  d1 <- c.loc + n.j
  d2 <- d1 + 1
  d3 <- c.top + tot.tab
  d4 <- d3 + 1
  
  ca <- (c.loc+n.tab*d.loc)*(c.top+K*d.top)
  no.sum1 <- ca*(1-d.loc)
  no.sum2 <- ca*(c.loc+(n.tab+1)*d.loc)*(1-d.top)
  
  # Managed to vectorize this!
  # sum.t1 <- 0
  # sum.t2 <- 0
  # for (t in 1:n.tab) {
  #   c.sp <- c.tab[t, 1] # Get species for this table
  #   cd <- (c.tab[t,2]-d.loc)
  #   sum.t1 <- sum.t1 + cd*(Y[pop,c.sp]+1-(n.s.tab[pop,c.sp]+1)*d.loc)
  #   sum.t2 <- sum.t2 + cd*(n.tab.sp[c.sp]-d.top)
  # }
  
  sp.vec <- c.tab[, 1]
  sum.t1 <- sum((c.tab[,2]-d.loc)*(Y[pop,sp.vec]+1-(n.s.tab[pop,sp.vec]+1)*d.loc))
  sum.t2 <- sum((c.tab[,2]-d.loc)*(n.tab.sp[sp.vec]-d.top))
  
  # Managed to vectorize this!
  # sum.k1 <- 0
  # sum.k2 <- 0
  # for (k in 1:K) {
  #   mk <- (n.tab.sp[k]-d.top)
  #   sum.k1 <- sum.k1 + mk*(Y[pop,k]+1-(n.s.tab[pop,k]+1)*d.loc)
  #   sum.k2 <- sum.k2 + mk*(c.loc+(n.tab+1)*d.loc)*(n.tab.sp[k]+1-d.top)
  # }
  
  sum.k1 <- sum((n.tab.sp-d.top)*(Y[pop,]+1-(n.s.tab[pop,]+1)*d.loc))
  sum.k2 <- sum((n.tab.sp-d.top)*(c.loc+(n.tab+1)*d.loc)*(n.tab.sp+1-d.top))
  
  d <- sum.t1/(d1*d2) + (c.loc+n.tab*d.loc)*(sum.t2/(d1*d2*d3) + sum.k1/(d1*d2*d3) + sum.k2/(d1*d2*d3*d4)) +
                                        no.sum1/(d1*d2*d3) + no.sum2/(d1*d2*d3*d4)
  
  return(1-d)
}

#' Get Simpson's diversity index based on estimated hierarchical Pitman-Yor model (old version)
#'
#' @return
#' @export
#'
#' @examples
getSimpsonOld <- function(tab, n.s.tab, pop, c.top, d.top, c.local, d.local) {
  
  # Current table frequencies
  c.tab <- tab[[pop]]
  n.tab <- NROW(c.tab)
  n.j <- sum(c.tab[,2])
  n.tab.sp <- colSums(n.s.tab) # Number of tables of each species over all populations
  tot.tab <- sum(n.tab.sp) # Number of tables overall
  K <- length(n.tab.sp)
  
  index <- 0
  for (t in 1:n.tab) {
    c.sp <- c.tab[t, 1] # Get species for this table
    t.ss <- which(c.tab[,1]==c.sp) # Which other tables are of the same species as the current one?
    t.ss <- t.ss[t.ss!=t]
    #t.t.sp <- lapply(tab, function(x){sum(x[x[1,]==c.sp,2])})
    incr <- (c.tab[t,2]-d.local)/(c.local+n.j-1)*((c.tab[t,2]+1-d.local)/(c.local+n.j)+
                                                    sum((c.tab[t.ss,2]-d.local)/(c.local+n.j))+
                                                    (c.local+n.tab*d.local)/(c.local+n.j)*(n.tab.sp[c.sp]-d.top)/(c.top+tot.tab-1))+
      (c.local+n.tab*d.local)/(c.local+n.j-1)*((c.top+K*d.top)/(c.top+tot.tab-1)*((1-d.local)/(c.local+n.j)+(c.local+(n.tab+1)*d.local)/(c.local+n.j)*(1-d.top)/(c.top+tot.tab))+
                                                 (n.tab.sp[c.sp]-d.top)/(c.top+tot.tab-1)*((1-d.local)/(c.local+n.j)+sum((c.tab[t.ss,2]-d.local)/(c.local+n.j))+(c.local+(n.tab+1)*d.local)/(c.local+n.j)*(n.tab.sp[c.sp]+1-d.top)/(c.top+tot.tab)))
    index <- index + incr
  }
  
  return(1-index)
}

getSimpsonBeta <- function(Y, tab, n.s.tab, pop1, pop2, c.top, d.top, c.loc1, d.loc1, c.loc2, d.loc2) {
  
  Y.1 <- Y[pop1,] # Species frequencies for this population
  Y.2 <- Y[pop2,]
  c.tab1 <- tab[[pop1]]
  c.tab2 <- tab[[pop2]]
  n.tab1 <- NROW(c.tab1)
  n.tab2 <- NROW(c.tab2)
  n.1 <- sum(c.tab1[,2])
  n.2 <- sum(c.tab2[,2])
  n.tab.sp <- colSums(n.s.tab) # Number of tables of each species over all populations
  tot.tab <- sum(n.tab.sp) # Number of tables overall
  K <- NCOL(n.tab.sp)
  
  den <- (c.loc1+n.1-1)*(c.loc2+n.2-1)*(c.top+tot.tab-1)*(c.top+tot.tab)
  sum1 <- sum2 <- sum3 <- 0
  # Outer loop is over tables in first population
  for (t in 1:n.tab1) {
    c.sp <- c.tab1[t, 1] # Get species for this table
    t.ss <- which(c.tab2[,1]==c.sp) # Which tables in the second population are of the same species as the current one?
    sum1 <- sum1 + (c.tab1[t,2]-d.loc1)*((c.top+tot.tab-1)*(Y.2[c.sp]-n.s.tab[pop2,c.sp]*d.loc2)+(c.loc2+n.tab2*d.loc2)*(n.tab.sp[c.sp]-d.top))
    sum2 <- sum2 + (n.tab.sp[c.sp]-d.top)*(Y.2[c.sp]-n.s.tab[pop2,c.sp]*d.loc2)
    sum3 <- sum3 + (n.tab.sp[c.sp]-d.top)*(n.tab.sp[c.sp]+1-d.top)
  }
  
  d <- ((c.top+tot.tab)*(sum1+(c.loc1+n.tab1*d.loc1)*sum2) +
          (c.loc1+n.tab1*d.loc1)*((c.loc2+n.tab2*d.loc2)*(n.tab1*(c.top+K*d.top)*(1-d.top)+sum3)))/den
  return(1-d)
}

# Might have made mistake in getSimpsonBeta... checking
getSimpsonBetaTry <- function(Y, tab, n.s.tab, pop1, pop2, c.top, d.top, c.loc1, d.loc1, c.loc2, d.loc2) {
  
  Y.1 <- Y[pop1,] # Species frequencies for this population
  Y.2 <- Y[pop2,]
  c.tab1 <- tab[[pop1]]
  c.tab2 <- tab[[pop2]]
  n.tab1 <- NROW(c.tab1)
  n.tab2 <- NROW(c.tab2)
  n.1 <- sum(c.tab1[,2])
  n.2 <- sum(c.tab2[,2])
  n.tab.sp <- colSums(n.s.tab) # Number of tables of each species over all populations
  tot.tab <- sum(n.tab.sp) # Number of tables overall
  K <- NCOL(n.tab.sp)
  
  d1 <- c.loc1 + n.1
  d2 <- c.loc2 + n.2
  d3 <- c.top + tot.tab
  d4 <- d3 + 1
  
  no.sum <- (c.top+K*d.top)*(c.loc2+n.tab2*d.loc2)*(1-d.top)
  
  sp.vec <- c.tab1[, 1]
  cd <- (c.tab1[,2]-d.loc1)
  t.sum1 <- sum(cd*(Y.2[sp.vec]-n.s.tab[pop2,sp.vec]*d.loc2))
  t.sum2 <- sum(cd*(n.tab.sp[sp.vec]-d.top))
  
  nk <- (n.tab.sp-d.top)
  k.sum1 <- sum(nk*(Y.2-n.s.tab[pop2,]*d.loc2))
  k.sum2 <- (c.loc2+n.tab2*d.loc2)*sum(nk*(n.tab.sp+1-d.top))
  
  d <- t.sum1/(d1*d2) + (c.loc2+n.tab2*d.loc2)*t.sum2/(d1*d2*d3) + (c.loc1+n.tab1*d.loc1)*(
      (no.sum+k.sum2)/(d1*d2*d3*d4) + k.sum1/(d1*d2*d3))
  return(1-d)
}

# Older less efficient version
# ALSO WRONG!!!
getSimpsonBetaOld <- function(tab, n.s.tab, pop1, pop2, c.top, d.top, c.local1, d.local1, c.local2, d.local2) {
  
  c.tab1 <- tab[[pop1]]
  c.tab2 <- tab[[pop2]]
  n.tab1 <- NROW(c.tab1)
  n.tab2 <- NROW(c.tab2)
  n.1 <- sum(c.tab1[,2])
  n.2 <- sum(c.tab2[,2])
  n.tab.sp <- colSums(n.s.tab) # Number of tables of each species over all populations
  tot.tab <- sum(n.tab.sp) # Number of tables overall
  K <- NCOL(n.tab.sp)
  
  index <- 0
  # Outer loop is over tables in first population
  for (t in 1:n.tab1) {
    c.sp <- c.tab1[t, 1] # Get species for this table
    t.ss <- which(c.tab2[,1]==c.sp) # Which tables in the second population are of the same species as the current one?
    incr <- (c.tab1[t,2]-d.local1)/(c.local1+n.1-1)*(sum((c.tab2[t.ss,2]-d.local2)/(c.local2+n.2-1)) +
                                                       (c.local2+n.tab2*d.local2)/(c.local2+n.2-1)*(n.tab.sp[c.sp]-d.top)/(c.top+tot.tab-1)) +
      (c.local1+n.tab1*d.local1)/(c.local1+n.1-1)* 
      ((c.top+K*d.top)/(c.top+tot.tab-1)*(c.local2+n.tab2*d.local2)/(c.local2+n.2-1)*(1-d.top)/(c.top+tot.tab) +
         (n.tab.sp[c.sp]-d.top)/(c.top+tot.tab-1)*(sum((c.tab2[t.ss,2]-d.local2)/(c.local2+n.2-1)) 
                                                   + (c.local2+n.tab2*d.local2)/(c.local2+n.2-1)*(n.tab.sp[c.sp]+1-d.top)/(c.top+tot.tab)))
    index <- index + incr
  }
  
  return(1-index)
}


# Unconditional Simpson's index
# Only uses HPY parameters, no counts or table indicators
getSimpsonUnconditional <- function(c.top, d.top, c.loc, d.loc) {
  1 - (1-d.loc)/(c.loc+1) - (c.loc+d.loc)/(c.loc+1)*(1-d.top)/(c.top+1)
}

# Unconditional Simpson's index for beta diversity
# Only uses HPY parameters, no counts or table indicators
getSimpsonBetaUnconditional <- function(c.top, d.top) {
  1 - (1-d.top)/(c.top+1)
}



